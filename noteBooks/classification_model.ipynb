{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "classification_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f78bfa4d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "id": "f78bfa4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fe8f044"
      },
      "source": [
        "#load the data set\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "#Split the data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#name of images\n",
        "class_names = ['T-shirt', 'trousers', 'pullover', 'dress', 'coat',\n",
        "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# reshaping\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "# Normalize the data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Performing one hot encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "id": "1fe8f044",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a99013db"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "classifier.add(MaxPooling2D(pool_size=2))\n",
        "classifier.add(Dropout(0.3))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(256, activation='relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(10, activation='softmax'))\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "id": "a99013db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ab35cef",
        "outputId": "518aa706-3bcc-4ef2-f3fb-5db30447fde9"
      },
      "source": [
        "# Fit the model\n",
        "history = classifier.fit(x_train, y_train,\n",
        "          batch_size=86,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "id": "3ab35cef",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "698/698 [==============================] - 71s 102ms/step - loss: 0.4878 - accuracy: 0.8274 - val_loss: 0.3406 - val_accuracy: 0.8761\n",
            "Epoch 2/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.3334 - accuracy: 0.8800 - val_loss: 0.2946 - val_accuracy: 0.8927\n",
            "Epoch 3/100\n",
            "698/698 [==============================] - 59s 84ms/step - loss: 0.2955 - accuracy: 0.8932 - val_loss: 0.2784 - val_accuracy: 0.8977\n",
            "Epoch 4/100\n",
            "698/698 [==============================] - 63s 90ms/step - loss: 0.2737 - accuracy: 0.8994 - val_loss: 0.2671 - val_accuracy: 0.9012\n",
            "Epoch 5/100\n",
            "698/698 [==============================] - 58s 84ms/step - loss: 0.2523 - accuracy: 0.9077 - val_loss: 0.2623 - val_accuracy: 0.9037\n",
            "Epoch 6/100\n",
            "698/698 [==============================] - 59s 85ms/step - loss: 0.2384 - accuracy: 0.9126 - val_loss: 0.2661 - val_accuracy: 0.9035\n",
            "Epoch 7/100\n",
            "698/698 [==============================] - 57s 81ms/step - loss: 0.2277 - accuracy: 0.9156 - val_loss: 0.2481 - val_accuracy: 0.9096\n",
            "Epoch 8/100\n",
            "698/698 [==============================] - 61s 87ms/step - loss: 0.2164 - accuracy: 0.9196 - val_loss: 0.2485 - val_accuracy: 0.9098\n",
            "Epoch 9/100\n",
            "698/698 [==============================] - 60s 86ms/step - loss: 0.2071 - accuracy: 0.9229 - val_loss: 0.2402 - val_accuracy: 0.9125\n",
            "Epoch 10/100\n",
            "698/698 [==============================] - 58s 83ms/step - loss: 0.1979 - accuracy: 0.9276 - val_loss: 0.2430 - val_accuracy: 0.9129\n",
            "Epoch 11/100\n",
            "698/698 [==============================] - 58s 83ms/step - loss: 0.1890 - accuracy: 0.9294 - val_loss: 0.2512 - val_accuracy: 0.9114\n",
            "Epoch 12/100\n",
            "698/698 [==============================] - 58s 84ms/step - loss: 0.1816 - accuracy: 0.9319 - val_loss: 0.2410 - val_accuracy: 0.9158\n",
            "Epoch 13/100\n",
            "698/698 [==============================] - 58s 84ms/step - loss: 0.1787 - accuracy: 0.9329 - val_loss: 0.2396 - val_accuracy: 0.9162\n",
            "Epoch 14/100\n",
            "698/698 [==============================] - 58s 83ms/step - loss: 0.1704 - accuracy: 0.9367 - val_loss: 0.2439 - val_accuracy: 0.9161\n",
            "Epoch 15/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.1649 - accuracy: 0.9387 - val_loss: 0.2382 - val_accuracy: 0.9164\n",
            "Epoch 16/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.1575 - accuracy: 0.9410 - val_loss: 0.2376 - val_accuracy: 0.9203\n",
            "Epoch 17/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.1539 - accuracy: 0.9420 - val_loss: 0.2437 - val_accuracy: 0.9168\n",
            "Epoch 18/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.1484 - accuracy: 0.9447 - val_loss: 0.2406 - val_accuracy: 0.9180\n",
            "Epoch 19/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.1437 - accuracy: 0.9459 - val_loss: 0.2476 - val_accuracy: 0.9198\n",
            "Epoch 20/100\n",
            "698/698 [==============================] - 60s 86ms/step - loss: 0.1400 - accuracy: 0.9470 - val_loss: 0.2431 - val_accuracy: 0.9198\n",
            "Epoch 21/100\n",
            "698/698 [==============================] - 56s 80ms/step - loss: 0.1368 - accuracy: 0.9480 - val_loss: 0.2475 - val_accuracy: 0.9211\n",
            "Epoch 22/100\n",
            "698/698 [==============================] - 56s 80ms/step - loss: 0.1320 - accuracy: 0.9503 - val_loss: 0.2501 - val_accuracy: 0.9199\n",
            "Epoch 23/100\n",
            "698/698 [==============================] - 59s 84ms/step - loss: 0.1307 - accuracy: 0.9512 - val_loss: 0.2547 - val_accuracy: 0.9200\n",
            "Epoch 24/100\n",
            "698/698 [==============================] - 61s 87ms/step - loss: 0.1269 - accuracy: 0.9518 - val_loss: 0.2613 - val_accuracy: 0.9197\n",
            "Epoch 25/100\n",
            "698/698 [==============================] - 58s 83ms/step - loss: 0.1233 - accuracy: 0.9538 - val_loss: 0.2651 - val_accuracy: 0.9196\n",
            "Epoch 26/100\n",
            "698/698 [==============================] - 58s 82ms/step - loss: 0.1189 - accuracy: 0.9546 - val_loss: 0.2632 - val_accuracy: 0.9193\n",
            "Epoch 27/100\n",
            "698/698 [==============================] - 63s 90ms/step - loss: 0.1197 - accuracy: 0.9546 - val_loss: 0.2628 - val_accuracy: 0.9205\n",
            "Epoch 28/100\n",
            "698/698 [==============================] - 59s 85ms/step - loss: 0.1128 - accuracy: 0.9562 - val_loss: 0.2657 - val_accuracy: 0.9232\n",
            "Epoch 29/100\n",
            "698/698 [==============================] - 56s 81ms/step - loss: 0.1093 - accuracy: 0.9592 - val_loss: 0.2637 - val_accuracy: 0.9211\n",
            "Epoch 30/100\n",
            "698/698 [==============================] - 53s 77ms/step - loss: 0.1087 - accuracy: 0.9584 - val_loss: 0.2745 - val_accuracy: 0.9213\n",
            "Epoch 31/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.1070 - accuracy: 0.9589 - val_loss: 0.2709 - val_accuracy: 0.9220\n",
            "Epoch 32/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.1037 - accuracy: 0.9603 - val_loss: 0.2903 - val_accuracy: 0.9219\n",
            "Epoch 33/100\n",
            "698/698 [==============================] - 57s 82ms/step - loss: 0.1013 - accuracy: 0.9608 - val_loss: 0.2791 - val_accuracy: 0.9244\n",
            "Epoch 34/100\n",
            "698/698 [==============================] - 64s 91ms/step - loss: 0.0978 - accuracy: 0.9632 - val_loss: 0.2890 - val_accuracy: 0.9220\n",
            "Epoch 35/100\n",
            "698/698 [==============================] - 65s 93ms/step - loss: 0.1001 - accuracy: 0.9619 - val_loss: 0.2840 - val_accuracy: 0.9228\n",
            "Epoch 36/100\n",
            "698/698 [==============================] - 59s 85ms/step - loss: 0.0964 - accuracy: 0.9632 - val_loss: 0.2877 - val_accuracy: 0.9215\n",
            "Epoch 37/100\n",
            "698/698 [==============================] - 56s 80ms/step - loss: 0.0954 - accuracy: 0.9646 - val_loss: 0.2830 - val_accuracy: 0.9230\n",
            "Epoch 38/100\n",
            "698/698 [==============================] - 54s 77ms/step - loss: 0.0932 - accuracy: 0.9637 - val_loss: 0.2902 - val_accuracy: 0.9218\n",
            "Epoch 39/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0909 - accuracy: 0.9655 - val_loss: 0.2917 - val_accuracy: 0.9239\n",
            "Epoch 40/100\n",
            "698/698 [==============================] - 53s 77ms/step - loss: 0.0906 - accuracy: 0.9654 - val_loss: 0.2935 - val_accuracy: 0.9228\n",
            "Epoch 41/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0887 - accuracy: 0.9661 - val_loss: 0.2975 - val_accuracy: 0.9224\n",
            "Epoch 42/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0884 - accuracy: 0.9669 - val_loss: 0.3003 - val_accuracy: 0.9235\n",
            "Epoch 43/100\n",
            "698/698 [==============================] - 55s 78ms/step - loss: 0.0856 - accuracy: 0.9670 - val_loss: 0.3014 - val_accuracy: 0.9239\n",
            "Epoch 44/100\n",
            "698/698 [==============================] - 54s 77ms/step - loss: 0.0841 - accuracy: 0.9680 - val_loss: 0.3059 - val_accuracy: 0.9236\n",
            "Epoch 45/100\n",
            "698/698 [==============================] - 55s 78ms/step - loss: 0.0840 - accuracy: 0.9679 - val_loss: 0.3081 - val_accuracy: 0.9219\n",
            "Epoch 46/100\n",
            "698/698 [==============================] - 58s 83ms/step - loss: 0.0835 - accuracy: 0.9689 - val_loss: 0.3052 - val_accuracy: 0.9217\n",
            "Epoch 47/100\n",
            "698/698 [==============================] - 57s 81ms/step - loss: 0.0845 - accuracy: 0.9672 - val_loss: 0.3089 - val_accuracy: 0.9242\n",
            "Epoch 48/100\n",
            "698/698 [==============================] - 55s 78ms/step - loss: 0.0808 - accuracy: 0.9685 - val_loss: 0.3166 - val_accuracy: 0.9242\n",
            "Epoch 49/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0797 - accuracy: 0.9700 - val_loss: 0.3143 - val_accuracy: 0.9239\n",
            "Epoch 50/100\n",
            "698/698 [==============================] - 57s 82ms/step - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.3252 - val_accuracy: 0.9227\n",
            "Epoch 51/100\n",
            "698/698 [==============================] - 58s 84ms/step - loss: 0.0790 - accuracy: 0.9699 - val_loss: 0.3311 - val_accuracy: 0.9238\n",
            "Epoch 52/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0783 - accuracy: 0.9714 - val_loss: 0.3247 - val_accuracy: 0.9249\n",
            "Epoch 53/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0767 - accuracy: 0.9712 - val_loss: 0.3213 - val_accuracy: 0.9207\n",
            "Epoch 54/100\n",
            "698/698 [==============================] - 55s 78ms/step - loss: 0.0746 - accuracy: 0.9714 - val_loss: 0.3213 - val_accuracy: 0.9214\n",
            "Epoch 55/100\n",
            "698/698 [==============================] - 57s 81ms/step - loss: 0.0754 - accuracy: 0.9719 - val_loss: 0.3437 - val_accuracy: 0.9234\n",
            "Epoch 56/100\n",
            "698/698 [==============================] - 56s 80ms/step - loss: 0.0731 - accuracy: 0.9718 - val_loss: 0.3319 - val_accuracy: 0.9230\n",
            "Epoch 57/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "698/698 [==============================] - 54s 77ms/step - loss: 0.0721 - accuracy: 0.9737 - val_loss: 0.3288 - val_accuracy: 0.9233\n",
            "Epoch 58/100\n",
            "698/698 [==============================] - 52s 75ms/step - loss: 0.0715 - accuracy: 0.9727 - val_loss: 0.3344 - val_accuracy: 0.9233\n",
            "Epoch 59/100\n",
            "698/698 [==============================] - 52s 74ms/step - loss: 0.0674 - accuracy: 0.9740 - val_loss: 0.3437 - val_accuracy: 0.9232\n",
            "Epoch 60/100\n",
            "698/698 [==============================] - 52s 75ms/step - loss: 0.0719 - accuracy: 0.9723 - val_loss: 0.3482 - val_accuracy: 0.9228\n",
            "Epoch 61/100\n",
            "698/698 [==============================] - 52s 75ms/step - loss: 0.0710 - accuracy: 0.9739 - val_loss: 0.3504 - val_accuracy: 0.9227\n",
            "Epoch 62/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0684 - accuracy: 0.9742 - val_loss: 0.3505 - val_accuracy: 0.9213\n",
            "Epoch 63/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0675 - accuracy: 0.9746 - val_loss: 0.3423 - val_accuracy: 0.9224\n",
            "Epoch 64/100\n",
            "698/698 [==============================] - 54s 78ms/step - loss: 0.0688 - accuracy: 0.9741 - val_loss: 0.3632 - val_accuracy: 0.9206\n",
            "Epoch 65/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0684 - accuracy: 0.9743 - val_loss: 0.3530 - val_accuracy: 0.9239\n",
            "Epoch 66/100\n",
            "698/698 [==============================] - 60s 85ms/step - loss: 0.0698 - accuracy: 0.9739 - val_loss: 0.3384 - val_accuracy: 0.9231\n",
            "Epoch 67/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0653 - accuracy: 0.9747 - val_loss: 0.3578 - val_accuracy: 0.9252\n",
            "Epoch 68/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0656 - accuracy: 0.9751 - val_loss: 0.3578 - val_accuracy: 0.9233\n",
            "Epoch 69/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0621 - accuracy: 0.9772 - val_loss: 0.3520 - val_accuracy: 0.9236\n",
            "Epoch 70/100\n",
            "698/698 [==============================] - 52s 75ms/step - loss: 0.0655 - accuracy: 0.9745 - val_loss: 0.3389 - val_accuracy: 0.9235\n",
            "Epoch 71/100\n",
            "698/698 [==============================] - 52s 75ms/step - loss: 0.0621 - accuracy: 0.9765 - val_loss: 0.3746 - val_accuracy: 0.9207\n",
            "Epoch 72/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0648 - accuracy: 0.9759 - val_loss: 0.3667 - val_accuracy: 0.9222\n",
            "Epoch 73/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0669 - accuracy: 0.9752 - val_loss: 0.3731 - val_accuracy: 0.9217\n",
            "Epoch 74/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0606 - accuracy: 0.9774 - val_loss: 0.3821 - val_accuracy: 0.9222\n",
            "Epoch 75/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0631 - accuracy: 0.9761 - val_loss: 0.3755 - val_accuracy: 0.9218\n",
            "Epoch 76/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0654 - accuracy: 0.9759 - val_loss: 0.3582 - val_accuracy: 0.9190\n",
            "Epoch 77/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0610 - accuracy: 0.9776 - val_loss: 0.3717 - val_accuracy: 0.9249\n",
            "Epoch 78/100\n",
            "698/698 [==============================] - 54s 78ms/step - loss: 0.0587 - accuracy: 0.9781 - val_loss: 0.3832 - val_accuracy: 0.9239\n",
            "Epoch 79/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0609 - accuracy: 0.9776 - val_loss: 0.3785 - val_accuracy: 0.9230\n",
            "Epoch 80/100\n",
            "698/698 [==============================] - 58s 84ms/step - loss: 0.0603 - accuracy: 0.9776 - val_loss: 0.3709 - val_accuracy: 0.9224\n",
            "Epoch 81/100\n",
            "698/698 [==============================] - 54s 77ms/step - loss: 0.0599 - accuracy: 0.9775 - val_loss: 0.3821 - val_accuracy: 0.9268\n",
            "Epoch 82/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0580 - accuracy: 0.9783 - val_loss: 0.3783 - val_accuracy: 0.9243\n",
            "Epoch 83/100\n",
            "698/698 [==============================] - 54s 77ms/step - loss: 0.0602 - accuracy: 0.9776 - val_loss: 0.3668 - val_accuracy: 0.9227\n",
            "Epoch 84/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0576 - accuracy: 0.9786 - val_loss: 0.3966 - val_accuracy: 0.9214\n",
            "Epoch 85/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0581 - accuracy: 0.9781 - val_loss: 0.4058 - val_accuracy: 0.9221\n",
            "Epoch 86/100\n",
            "698/698 [==============================] - 53s 75ms/step - loss: 0.0593 - accuracy: 0.9784 - val_loss: 0.4010 - val_accuracy: 0.9215\n",
            "Epoch 87/100\n",
            "698/698 [==============================] - 52s 75ms/step - loss: 0.0585 - accuracy: 0.9787 - val_loss: 0.3997 - val_accuracy: 0.9235\n",
            "Epoch 88/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0580 - accuracy: 0.9786 - val_loss: 0.3910 - val_accuracy: 0.9241\n",
            "Epoch 89/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.3672 - val_accuracy: 0.9256\n",
            "Epoch 90/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0578 - accuracy: 0.9781 - val_loss: 0.3926 - val_accuracy: 0.9201\n",
            "Epoch 91/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0573 - accuracy: 0.9790 - val_loss: 0.3871 - val_accuracy: 0.9233\n",
            "Epoch 92/100\n",
            "698/698 [==============================] - 53s 77ms/step - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.3917 - val_accuracy: 0.9241\n",
            "Epoch 93/100\n",
            "698/698 [==============================] - 54s 77ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.3940 - val_accuracy: 0.9213\n",
            "Epoch 94/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0560 - accuracy: 0.9798 - val_loss: 0.4000 - val_accuracy: 0.9235\n",
            "Epoch 95/100\n",
            "698/698 [==============================] - 53s 76ms/step - loss: 0.0552 - accuracy: 0.9792 - val_loss: 0.3929 - val_accuracy: 0.9220\n",
            "Epoch 96/100\n",
            "698/698 [==============================] - 55s 79ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.4045 - val_accuracy: 0.9229\n",
            "Epoch 97/100\n",
            "698/698 [==============================] - 55s 78ms/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.4094 - val_accuracy: 0.9241\n",
            "Epoch 98/100\n",
            "698/698 [==============================] - 53s 77ms/step - loss: 0.0543 - accuracy: 0.9803 - val_loss: 0.4180 - val_accuracy: 0.9224\n",
            "Epoch 99/100\n",
            "698/698 [==============================] - 53s 77ms/step - loss: 0.0561 - accuracy: 0.9791 - val_loss: 0.4034 - val_accuracy: 0.9216\n",
            "Epoch 100/100\n",
            "698/698 [==============================] - 53s 77ms/step - loss: 0.0540 - accuracy: 0.9809 - val_loss: 0.4200 - val_accuracy: 0.9218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5028c4b1",
        "outputId": "53141221-c511-4bc8-aa9d-f5069d65dbef"
      },
      "source": [
        "plt.subplot(231)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "id": "5028c4b1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a97f5ae0",
        "outputId": "b47a8181-e5ab-43f9-c736-c11ff1cdc269"
      },
      "source": [
        "#Predict the test results\n",
        "rounded_predictions = classifier.predict_classes(x_test)\n",
        "rounded_predictions[1]\n",
        "\n",
        "y_test[1]\n",
        "import numpy as np\n",
        "rounded_labels=np.argmax(y_test, axis=1)\n",
        "rounded_labels[1]\n",
        "\n",
        "#confusion matrix and classification report\n",
        "print('Confusion Matrix :\\n',confusion_matrix(rounded_labels, rounded_predictions))\n",
        "print('\\n')\n",
        "print('Classification Report :\\n',classification_report(rounded_labels, rounded_predictions))\n",
        "print('\\n')\n",
        "print('Accuracy : ' ,accuracy_score(rounded_labels, rounded_predictions)*100)"
      ],
      "id": "a97f5ae0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-fdb8036ab5c9>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Confusion Matrix :\n",
            " [[890   0  15  18   3   1  69   0   4   0]\n",
            " [  0 982   1  11   3   0   1   0   2   0]\n",
            " [ 17   0 887  11  39   0  46   0   0   0]\n",
            " [ 12   4   8 935  23   0  17   0   1   0]\n",
            " [  1   1  77  24 858   0  38   0   1   0]\n",
            " [  0   0   0   0   0 975   0  18   0   7]\n",
            " [101   2  55  21  56   0 757   0   8   0]\n",
            " [  0   0   0   0   0   0   0 987   0  13]\n",
            " [  1   1   0   7   0   2   4   4 981   0]\n",
            " [  0   0   0   0   0   3   1  30   0 966]]\n",
            "\n",
            "\n",
            "Classification Report :\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.85      0.89      0.87      1000\n",
            "           3       0.91      0.94      0.92      1000\n",
            "           4       0.87      0.86      0.87      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.81      0.76      0.78      1000\n",
            "           7       0.95      0.99      0.97      1000\n",
            "           8       0.98      0.98      0.98      1000\n",
            "           9       0.98      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "\n",
            "Accuracy :  92.17999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2a9cb04",
        "outputId": "525a66d2-0750-4c45-8f8a-80cbeeb592db"
      },
      "source": [
        "loss, acc = classifier.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy: %.3f' % acc)\n",
        "classifier.save('classificationAvecMatrix.h5')"
      ],
      "id": "e2a9cb04",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f786946"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "batches = datagen.flow(x_train, y_train, batch_size=64)"
      ],
      "id": "8f786946",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b7ff842",
        "outputId": "e586d22e-3547-4d0f-a847-e7ee9b419e7f"
      },
      "source": [
        "classifier.fit(batches, steps_per_epoch = len(x_train)//64, epochs=100,\n",
        "                      use_multiprocessing=False)"
      ],
      "id": "9b7ff842",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "937/937 [==============================] - 91s 97ms/step - loss: 0.7185 - accuracy: 0.7437\n",
            "Epoch 2/100\n",
            "937/937 [==============================] - 86s 92ms/step - loss: 0.5857 - accuracy: 0.7839\n",
            "Epoch 3/100\n",
            "937/937 [==============================] - 84s 90ms/step - loss: 0.5468 - accuracy: 0.7981\n",
            "Epoch 4/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.5286 - accuracy: 0.8043\n",
            "Epoch 5/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.5066 - accuracy: 0.8105\n",
            "Epoch 6/100\n",
            "937/937 [==============================] - 55s 59ms/step - loss: 0.4942 - accuracy: 0.8158\n",
            "Epoch 7/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.4811 - accuracy: 0.8218\n",
            "Epoch 8/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.4708 - accuracy: 0.8251\n",
            "Epoch 9/100\n",
            "937/937 [==============================] - 57s 61ms/step - loss: 0.4674 - accuracy: 0.8256\n",
            "Epoch 10/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.4584 - accuracy: 0.8287\n",
            "Epoch 11/100\n",
            "937/937 [==============================] - 56s 59ms/step - loss: 0.4550 - accuracy: 0.8298\n",
            "Epoch 12/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.4492 - accuracy: 0.8331\n",
            "Epoch 13/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.4461 - accuracy: 0.8332\n",
            "Epoch 14/100\n",
            "937/937 [==============================] - 63s 68ms/step - loss: 0.4393 - accuracy: 0.8360\n",
            "Epoch 15/100\n",
            "937/937 [==============================] - 57s 61ms/step - loss: 0.4353 - accuracy: 0.8387\n",
            "Epoch 16/100\n",
            "937/937 [==============================] - 55s 59ms/step - loss: 0.4360 - accuracy: 0.8377\n",
            "Epoch 17/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.4315 - accuracy: 0.8385\n",
            "Epoch 18/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.4259 - accuracy: 0.8434\n",
            "Epoch 19/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.4280 - accuracy: 0.8418\n",
            "Epoch 20/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.4198 - accuracy: 0.8438\n",
            "Epoch 21/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.4214 - accuracy: 0.8428\n",
            "Epoch 22/100\n",
            "937/937 [==============================] - 70s 75ms/step - loss: 0.4169 - accuracy: 0.8469\n",
            "Epoch 23/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.4149 - accuracy: 0.8475\n",
            "Epoch 24/100\n",
            "937/937 [==============================] - 57s 61ms/step - loss: 0.4131 - accuracy: 0.8468\n",
            "Epoch 25/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.4111 - accuracy: 0.8473\n",
            "Epoch 26/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.4086 - accuracy: 0.8476\n",
            "Epoch 27/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.4091 - accuracy: 0.8482\n",
            "Epoch 28/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.4065 - accuracy: 0.8493\n",
            "Epoch 29/100\n",
            "937/937 [==============================] - 64s 68ms/step - loss: 0.4082 - accuracy: 0.8483\n",
            "Epoch 30/100\n",
            "937/937 [==============================] - 67s 71ms/step - loss: 0.4064 - accuracy: 0.8499\n",
            "Epoch 31/100\n",
            "937/937 [==============================] - 67s 71ms/step - loss: 0.4000 - accuracy: 0.8513\n",
            "Epoch 32/100\n",
            "937/937 [==============================] - 64s 69ms/step - loss: 0.3991 - accuracy: 0.8516\n",
            "Epoch 33/100\n",
            "937/937 [==============================] - 73s 78ms/step - loss: 0.3966 - accuracy: 0.8527\n",
            "Epoch 34/100\n",
            "937/937 [==============================] - 69s 74ms/step - loss: 0.4027 - accuracy: 0.8491\n",
            "Epoch 35/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.3946 - accuracy: 0.8536\n",
            "Epoch 36/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.3922 - accuracy: 0.8534\n",
            "Epoch 37/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.3945 - accuracy: 0.8544\n",
            "Epoch 38/100\n",
            "937/937 [==============================] - 66s 71ms/step - loss: 0.3894 - accuracy: 0.8546\n",
            "Epoch 39/100\n",
            "937/937 [==============================] - 66s 70ms/step - loss: 0.3882 - accuracy: 0.8573\n",
            "Epoch 40/100\n",
            "937/937 [==============================] - 64s 68ms/step - loss: 0.3891 - accuracy: 0.8557\n",
            "Epoch 41/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.3896 - accuracy: 0.8558\n",
            "Epoch 42/100\n",
            "937/937 [==============================] - 64s 69ms/step - loss: 0.3893 - accuracy: 0.8566\n",
            "Epoch 43/100\n",
            "937/937 [==============================] - 62s 67ms/step - loss: 0.3926 - accuracy: 0.8546\n",
            "Epoch 44/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.3854 - accuracy: 0.8576\n",
            "Epoch 45/100\n",
            "937/937 [==============================] - 64s 68ms/step - loss: 0.3857 - accuracy: 0.8564\n",
            "Epoch 46/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3826 - accuracy: 0.8584\n",
            "Epoch 47/100\n",
            "937/937 [==============================] - 57s 60ms/step - loss: 0.3865 - accuracy: 0.8547\n",
            "Epoch 48/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3823 - accuracy: 0.8569\n",
            "Epoch 49/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3827 - accuracy: 0.8578\n",
            "Epoch 50/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.3818 - accuracy: 0.8556\n",
            "Epoch 51/100\n",
            "937/937 [==============================] - 57s 60ms/step - loss: 0.3819 - accuracy: 0.8567\n",
            "Epoch 52/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3798 - accuracy: 0.8586\n",
            "Epoch 53/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.3854 - accuracy: 0.8567\n",
            "Epoch 54/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3800 - accuracy: 0.85940s - loss: 0.3799 - \n",
            "Epoch 55/100\n",
            "937/937 [==============================] - 55s 59ms/step - loss: 0.3766 - accuracy: 0.8614\n",
            "Epoch 56/100\n",
            "937/937 [==============================] - 54s 58ms/step - loss: 0.3786 - accuracy: 0.8585\n",
            "Epoch 57/100\n",
            "937/937 [==============================] - 55s 58ms/step - loss: 0.3799 - accuracy: 0.8604\n",
            "Epoch 58/100\n",
            "937/937 [==============================] - 54s 58ms/step - loss: 0.3757 - accuracy: 0.8598\n",
            "Epoch 59/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.3744 - accuracy: 0.8611\n",
            "Epoch 60/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.3751 - accuracy: 0.8602\n",
            "Epoch 61/100\n",
            "937/937 [==============================] - 55s 59ms/step - loss: 0.3761 - accuracy: 0.86000s - loss: 0.3\n",
            "Epoch 62/100\n",
            "937/937 [==============================] - 56s 59ms/step - loss: 0.3760 - accuracy: 0.8608\n",
            "Epoch 63/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3758 - accuracy: 0.8600\n",
            "Epoch 64/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3747 - accuracy: 0.8609\n",
            "Epoch 65/100\n",
            "937/937 [==============================] - 55s 58ms/step - loss: 0.3773 - accuracy: 0.8609\n",
            "Epoch 66/100\n",
            "937/937 [==============================] - 63s 67ms/step - loss: 0.3722 - accuracy: 0.8627\n",
            "Epoch 67/100\n",
            "937/937 [==============================] - 65s 69ms/step - loss: 0.3718 - accuracy: 0.8621\n",
            "Epoch 68/100\n",
            "937/937 [==============================] - 53s 57ms/step - loss: 0.3720 - accuracy: 0.8617\n",
            "Epoch 69/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3747 - accuracy: 0.8603\n",
            "Epoch 70/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3710 - accuracy: 0.8615\n",
            "Epoch 71/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.3687 - accuracy: 0.8623\n",
            "Epoch 72/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.3733 - accuracy: 0.8594\n",
            "Epoch 73/100\n",
            "937/937 [==============================] - 57s 60ms/step - loss: 0.3719 - accuracy: 0.8634\n",
            "Epoch 74/100\n",
            "937/937 [==============================] - 63s 67ms/step - loss: 0.3720 - accuracy: 0.8623\n",
            "Epoch 75/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3658 - accuracy: 0.8649\n",
            "Epoch 76/100\n",
            "937/937 [==============================] - 62s 66ms/step - loss: 0.3714 - accuracy: 0.8624\n",
            "Epoch 77/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3683 - accuracy: 0.8629\n",
            "Epoch 78/100\n",
            "937/937 [==============================] - 57s 61ms/step - loss: 0.3690 - accuracy: 0.8640\n",
            "Epoch 79/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "937/937 [==============================] - 57s 61ms/step - loss: 0.3665 - accuracy: 0.8649\n",
            "Epoch 80/100\n",
            "937/937 [==============================] - 54s 58ms/step - loss: 0.3640 - accuracy: 0.8657\n",
            "Epoch 81/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3654 - accuracy: 0.8659\n",
            "Epoch 82/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.3658 - accuracy: 0.8646\n",
            "Epoch 83/100\n",
            "937/937 [==============================] - 55s 59ms/step - loss: 0.3678 - accuracy: 0.8638\n",
            "Epoch 84/100\n",
            "937/937 [==============================] - 54s 58ms/step - loss: 0.3675 - accuracy: 0.8634\n",
            "Epoch 85/100\n",
            "937/937 [==============================] - 59s 63ms/step - loss: 0.3621 - accuracy: 0.8648\n",
            "Epoch 86/100\n",
            "937/937 [==============================] - 55s 58ms/step - loss: 0.3623 - accuracy: 0.8648\n",
            "Epoch 87/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3619 - accuracy: 0.8655\n",
            "Epoch 88/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.3645 - accuracy: 0.8636\n",
            "Epoch 89/100\n",
            "937/937 [==============================] - 58s 62ms/step - loss: 0.3678 - accuracy: 0.8648\n",
            "Epoch 90/100\n",
            "937/937 [==============================] - 54s 58ms/step - loss: 0.3622 - accuracy: 0.8667\n",
            "Epoch 91/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.3642 - accuracy: 0.8649\n",
            "Epoch 92/100\n",
            "937/937 [==============================] - 56s 60ms/step - loss: 0.3621 - accuracy: 0.8658\n",
            "Epoch 93/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3623 - accuracy: 0.8672\n",
            "Epoch 94/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3622 - accuracy: 0.8653\n",
            "Epoch 95/100\n",
            "937/937 [==============================] - 62s 66ms/step - loss: 0.3627 - accuracy: 0.8638\n",
            "Epoch 96/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3622 - accuracy: 0.8646\n",
            "Epoch 97/100\n",
            "937/937 [==============================] - 60s 65ms/step - loss: 0.3612 - accuracy: 0.8672\n",
            "Epoch 98/100\n",
            "937/937 [==============================] - 61s 65ms/step - loss: 0.3613 - accuracy: 0.8649\n",
            "Epoch 99/100\n",
            "937/937 [==============================] - 62s 66ms/step - loss: 0.3649 - accuracy: 0.8636\n",
            "Epoch 100/100\n",
            "937/937 [==============================] - 60s 64ms/step - loss: 0.3591 - accuracy: 0.8667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2670fdae3a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94e1dcf4",
        "outputId": "af3a78d2-6d59-4a79-80e4-ab03f805337c"
      },
      "source": [
        "loss, acc = classifier.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "id": "94e1dcf4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52eb381f"
      },
      "source": [
        "classifier.save('classifierAugmentationAvecMatrix.h5')"
      ],
      "id": "52eb381f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40fe528e"
      },
      "source": [
        "# TESTE 1 AVEC \"LOAD_IMAGE\"\n"
      ],
      "id": "40fe528e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ca3f58"
      },
      "source": [
        "def plot_image(prediction, img):\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    predicted_label = np.argmax(prediction,axis = -1)\n",
        "    plt.xlabel(\"{} {:2.0f}%\".format(class_names[predicted_label],\n",
        "               100*np.max(prediction),\n",
        "               ),\n",
        "                color=\"blue\")\n",
        "    \n",
        "def plot_value_array(prediction):\n",
        "    plt.xticks(range(10))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), prediction, color=\"red\")\n",
        "    plt.ylim([0,1])\n",
        "    predicted_label = np.argmax(prediction)\n",
        "    thisplot[predicted_label].set_color('blue')"
      ],
      "id": "a3ca3f58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7852d32d",
        "outputId": "79a3d9a1-8676-48fd-bece-09723bfa3368"
      },
      "source": [
        "# Function to load and prepare the image in right shape\n",
        "def load_image(filename):\n",
        "    # Load the image\n",
        "    img = load_img(filename, color_mode = \"grayscale\", target_size=(28, 28))\n",
        "    # Convert the image to array\n",
        "    img = img_to_array(img)\n",
        "    # Reshape the image into a sample of 1 channel\n",
        "    img = img.reshape(1, 28, 28, 1)\n",
        "    # Prepare it as pixel data\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "# Load an image and predict the apparel class\n",
        "img = load_image('./ClassificationDimagesPageWeb/static/images/basquette.jpg')\n",
        "# Load the saved model\n",
        "classifier = load_model('classificationAvecMatrix.h5')\n",
        "# Predict the apparel class\n",
        "class_prediction = classifier.predict_classes(img)\n",
        "print(class_prediction[0])\n",
        "\n",
        "#Map apparel category with the numerical class\n",
        "if class_prediction[0] == 0:\n",
        "  product = \"T-shirt/top\"\n",
        "elif class_prediction[0] == 1:\n",
        "  product = \"Trouser\"\n",
        "elif class_prediction[0] == 2:\n",
        "  product = \"Pullover\"\n",
        "elif class_prediction[0] == 3:\n",
        "  product = \"Dress\"\n",
        "elif class_prediction[0] == 4:\n",
        "  product = \"Coat\"\n",
        "elif class_prediction[0] == 5:\n",
        "  product = \"Sandal\"\n",
        "elif class_prediction[0] == 6:\n",
        "  product = \"Shirt\"\n",
        "elif class_prediction[0] == 7:\n",
        "  product = \"Sneaker\"\n",
        "elif class_prediction[0] == 8:\n",
        "  product = \"Bag\"\n",
        "else:\n",
        "  product = \"Ankle boot\"\n",
        "\n",
        "print(product)\n"
      ],
      "id": "7852d32d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002672D0DBEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "7\n",
            "Sneaker\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdddb851"
      },
      "source": [
        "preds = classifier.predict(img)"
      ],
      "id": "bdddb851",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cd28fd5",
        "outputId": "799e28a4-0a0a-4137-daa5-d11ef9b01976"
      },
      "source": [
        "for i in range(1):\n",
        "    # image\n",
        "    plt.subplot(1, 2, 2*i+1)\n",
        "    plot_image(preds[i], img[i])\n",
        "    # bar chart\n",
        "    plt.subplot(1, 2, 2*i+2)\n",
        "    plot_value_array(preds[i])\n",
        "plt.show()"
      ],
      "id": "9cd28fd5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1619888539539,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "RE0-4hnJDMPV"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras import utils as np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1641,
     "status": "ok",
     "timestamp": 1619888542424,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "wqIQ6CXjDjrl",
    "outputId": "845c7313-21dc-4d80-89f8-8d400183f4f1"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "#name of images\n",
    "class_names = ['T-shirt', 'trousers', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "executionInfo": {
     "elapsed": 1150,
     "status": "ok",
     "timestamp": 1619888545938,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "NritxkDFKkFt",
    "outputId": "1cb242f7-030b-40ac-a3ce-4b986b9193e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting 5 images, Subplot arugments represent nrows, ncols and index\n",
    "# Color map is set to grey since our image dataset is grayscale\n",
    "plt.subplot(231)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.subplot(232)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.subplot(233)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1619888549086,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "uynTie22LaeQ"
   },
   "outputs": [],
   "source": [
    "taille_training_set = x_train.shape[0]\n",
    "taille_test_set = x_test.shape[0]\n",
    "\n",
    "# Storing the number of rows and columns\n",
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[1].shape[0]\n",
    "\n",
    "#Test data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Performing one hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6137,
     "status": "ok",
     "timestamp": 1619888558313,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "sRCZX0kVWcNl"
   },
   "outputs": [],
   "source": [
    "# Set the CNN model\n",
    "#initialisation du réseau de neurone\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 and 2 - Convolution / Pooling\n",
    "classifier.add(Conv2D(filters=64, kernel_size=7, strides=1, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2),strides=(2,2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection -couche connecté\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "# Couche de sortie\n",
    "classifier.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1619888562639,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "BGfMRDnxXIMr"
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642998,
     "status": "ok",
     "timestamp": 1619889209331,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "co-4QTGvXPgP",
    "outputId": "c5047858-6ce1-4248-e169-a10797158732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "698/698 [==============================] - 36s 5ms/step - loss: 0.6787 - accuracy: 0.7584 - val_loss: 0.3584 - val_accuracy: 0.8716\n",
      "Epoch 2/200\n",
      "698/698 [==============================] - 3s 5ms/step - loss: 0.3625 - accuracy: 0.8695 - val_loss: 0.3197 - val_accuracy: 0.8815\n",
      "Epoch 3/200\n",
      "698/698 [==============================] - 3s 5ms/step - loss: 0.3161 - accuracy: 0.8848 - val_loss: 0.2992 - val_accuracy: 0.8893\n",
      "Epoch 4/200\n",
      "698/698 [==============================] - 3s 5ms/step - loss: 0.2868 - accuracy: 0.8965 - val_loss: 0.2825 - val_accuracy: 0.8946\n",
      "Epoch 5/200\n",
      "698/698 [==============================] - 3s 5ms/step - loss: 0.2662 - accuracy: 0.9003 - val_loss: 0.2773 - val_accuracy: 0.8977\n",
      "Epoch 6/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.2526 - accuracy: 0.9050 - val_loss: 0.2620 - val_accuracy: 0.9036\n",
      "Epoch 7/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.2364 - accuracy: 0.9121 - val_loss: 0.2594 - val_accuracy: 0.9065\n",
      "Epoch 8/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.2214 - accuracy: 0.9170 - val_loss: 0.2495 - val_accuracy: 0.9089\n",
      "Epoch 9/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.2142 - accuracy: 0.9189 - val_loss: 0.2570 - val_accuracy: 0.9066\n",
      "Epoch 10/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.2027 - accuracy: 0.9248 - val_loss: 0.2504 - val_accuracy: 0.9109\n",
      "Epoch 11/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1941 - accuracy: 0.9271 - val_loss: 0.2521 - val_accuracy: 0.9107\n",
      "Epoch 12/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1857 - accuracy: 0.9285 - val_loss: 0.2514 - val_accuracy: 0.9137\n",
      "Epoch 13/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1771 - accuracy: 0.9332 - val_loss: 0.2444 - val_accuracy: 0.9168\n",
      "Epoch 14/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1742 - accuracy: 0.9335 - val_loss: 0.2468 - val_accuracy: 0.9130\n",
      "Epoch 15/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1641 - accuracy: 0.9370 - val_loss: 0.2464 - val_accuracy: 0.9155\n",
      "Epoch 16/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1578 - accuracy: 0.9398 - val_loss: 0.2571 - val_accuracy: 0.9154\n",
      "Epoch 17/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1509 - accuracy: 0.9432 - val_loss: 0.2610 - val_accuracy: 0.9153\n",
      "Epoch 18/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1501 - accuracy: 0.9415 - val_loss: 0.2636 - val_accuracy: 0.9164\n",
      "Epoch 19/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1427 - accuracy: 0.9460 - val_loss: 0.2635 - val_accuracy: 0.9166\n",
      "Epoch 20/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1354 - accuracy: 0.9478 - val_loss: 0.2623 - val_accuracy: 0.9183\n",
      "Epoch 21/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1370 - accuracy: 0.9464 - val_loss: 0.2810 - val_accuracy: 0.9157\n",
      "Epoch 22/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1339 - accuracy: 0.9479 - val_loss: 0.2717 - val_accuracy: 0.9149\n",
      "Epoch 23/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1290 - accuracy: 0.9506 - val_loss: 0.2679 - val_accuracy: 0.9183\n",
      "Epoch 24/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1223 - accuracy: 0.9531 - val_loss: 0.2721 - val_accuracy: 0.9191\n",
      "Epoch 25/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1207 - accuracy: 0.9538 - val_loss: 0.2812 - val_accuracy: 0.9199\n",
      "Epoch 26/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1170 - accuracy: 0.9536 - val_loss: 0.2815 - val_accuracy: 0.9219\n",
      "Epoch 27/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1092 - accuracy: 0.9590 - val_loss: 0.2875 - val_accuracy: 0.9180\n",
      "Epoch 28/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1119 - accuracy: 0.9562 - val_loss: 0.2849 - val_accuracy: 0.9219\n",
      "Epoch 29/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1084 - accuracy: 0.9570 - val_loss: 0.2831 - val_accuracy: 0.9208\n",
      "Epoch 30/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1057 - accuracy: 0.9588 - val_loss: 0.2877 - val_accuracy: 0.9180\n",
      "Epoch 31/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1055 - accuracy: 0.9596 - val_loss: 0.2948 - val_accuracy: 0.9206\n",
      "Epoch 32/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.1069 - accuracy: 0.9598 - val_loss: 0.2993 - val_accuracy: 0.9243\n",
      "Epoch 33/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0995 - accuracy: 0.9625 - val_loss: 0.3130 - val_accuracy: 0.9212\n",
      "Epoch 34/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0968 - accuracy: 0.9622 - val_loss: 0.3218 - val_accuracy: 0.9203\n",
      "Epoch 35/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0980 - accuracy: 0.9625 - val_loss: 0.3200 - val_accuracy: 0.9217\n",
      "Epoch 36/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0952 - accuracy: 0.9635 - val_loss: 0.3216 - val_accuracy: 0.9198\n",
      "Epoch 37/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0890 - accuracy: 0.9657 - val_loss: 0.3263 - val_accuracy: 0.9181\n",
      "Epoch 38/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0918 - accuracy: 0.9661 - val_loss: 0.3118 - val_accuracy: 0.9244\n",
      "Epoch 39/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0907 - accuracy: 0.9640 - val_loss: 0.3439 - val_accuracy: 0.9186\n",
      "Epoch 40/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0881 - accuracy: 0.9654 - val_loss: 0.3449 - val_accuracy: 0.9200\n",
      "Epoch 41/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0851 - accuracy: 0.9680 - val_loss: 0.3281 - val_accuracy: 0.9214\n",
      "Epoch 42/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9694 - val_loss: 0.3663 - val_accuracy: 0.9199\n",
      "Epoch 43/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0824 - accuracy: 0.9675 - val_loss: 0.3468 - val_accuracy: 0.9212\n",
      "Epoch 44/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0846 - accuracy: 0.9674 - val_loss: 0.3334 - val_accuracy: 0.9192\n",
      "Epoch 45/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0824 - accuracy: 0.9688 - val_loss: 0.3544 - val_accuracy: 0.9215\n",
      "Epoch 46/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0786 - accuracy: 0.9710 - val_loss: 0.3645 - val_accuracy: 0.9215\n",
      "Epoch 47/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0821 - accuracy: 0.9689 - val_loss: 0.3781 - val_accuracy: 0.9194\n",
      "Epoch 48/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0823 - accuracy: 0.9684 - val_loss: 0.3750 - val_accuracy: 0.9174\n",
      "Epoch 49/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0787 - accuracy: 0.9708 - val_loss: 0.3743 - val_accuracy: 0.9198\n",
      "Epoch 50/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0773 - accuracy: 0.9697 - val_loss: 0.3763 - val_accuracy: 0.9194\n",
      "Epoch 51/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0721 - accuracy: 0.9732 - val_loss: 0.3831 - val_accuracy: 0.9168\n",
      "Epoch 52/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0738 - accuracy: 0.9722 - val_loss: 0.3861 - val_accuracy: 0.9209\n",
      "Epoch 53/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0737 - accuracy: 0.9712 - val_loss: 0.3892 - val_accuracy: 0.9206\n",
      "Epoch 54/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0706 - accuracy: 0.9728 - val_loss: 0.4065 - val_accuracy: 0.9187\n",
      "Epoch 55/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0736 - accuracy: 0.9727 - val_loss: 0.3873 - val_accuracy: 0.9208\n",
      "Epoch 56/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0708 - accuracy: 0.9727 - val_loss: 0.4134 - val_accuracy: 0.9188\n",
      "Epoch 57/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0738 - accuracy: 0.9728 - val_loss: 0.4164 - val_accuracy: 0.9187\n",
      "Epoch 58/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0692 - accuracy: 0.9741 - val_loss: 0.4011 - val_accuracy: 0.9206\n",
      "Epoch 59/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0691 - accuracy: 0.9744 - val_loss: 0.4072 - val_accuracy: 0.9206\n",
      "Epoch 60/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0675 - accuracy: 0.9746 - val_loss: 0.4146 - val_accuracy: 0.9208\n",
      "Epoch 61/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0662 - accuracy: 0.9762 - val_loss: 0.3971 - val_accuracy: 0.9222\n",
      "Epoch 62/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0686 - accuracy: 0.9746 - val_loss: 0.4159 - val_accuracy: 0.9176\n",
      "Epoch 63/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0691 - accuracy: 0.9756 - val_loss: 0.3937 - val_accuracy: 0.9223\n",
      "Epoch 64/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0679 - accuracy: 0.9745 - val_loss: 0.4018 - val_accuracy: 0.9229\n",
      "Epoch 65/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0610 - accuracy: 0.9767 - val_loss: 0.4007 - val_accuracy: 0.9223\n",
      "Epoch 66/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0644 - accuracy: 0.9765 - val_loss: 0.4391 - val_accuracy: 0.9188\n",
      "Epoch 67/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0629 - accuracy: 0.9767 - val_loss: 0.4224 - val_accuracy: 0.9199\n",
      "Epoch 68/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0636 - accuracy: 0.9764 - val_loss: 0.4368 - val_accuracy: 0.9213\n",
      "Epoch 69/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0651 - accuracy: 0.9752 - val_loss: 0.4360 - val_accuracy: 0.9215\n",
      "Epoch 70/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0643 - accuracy: 0.9761 - val_loss: 0.4233 - val_accuracy: 0.9184\n",
      "Epoch 71/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0644 - accuracy: 0.9763 - val_loss: 0.4583 - val_accuracy: 0.9194\n",
      "Epoch 72/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0661 - accuracy: 0.9757 - val_loss: 0.4333 - val_accuracy: 0.9212\n",
      "Epoch 73/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0628 - accuracy: 0.9773 - val_loss: 0.4571 - val_accuracy: 0.9214\n",
      "Epoch 74/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.4512 - val_accuracy: 0.9176\n",
      "Epoch 75/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0623 - accuracy: 0.9759 - val_loss: 0.4236 - val_accuracy: 0.9222\n",
      "Epoch 76/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0579 - accuracy: 0.9789 - val_loss: 0.4735 - val_accuracy: 0.9204\n",
      "Epoch 77/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0624 - accuracy: 0.9775 - val_loss: 0.4580 - val_accuracy: 0.9197\n",
      "Epoch 78/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0617 - accuracy: 0.9780 - val_loss: 0.4981 - val_accuracy: 0.9183\n",
      "Epoch 79/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0550 - accuracy: 0.9796 - val_loss: 0.4908 - val_accuracy: 0.9178\n",
      "Epoch 80/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.4688 - val_accuracy: 0.9177\n",
      "Epoch 81/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0571 - accuracy: 0.9776 - val_loss: 0.4792 - val_accuracy: 0.9200\n",
      "Epoch 82/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0560 - accuracy: 0.9790 - val_loss: 0.4715 - val_accuracy: 0.9180\n",
      "Epoch 83/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0566 - accuracy: 0.9797 - val_loss: 0.4468 - val_accuracy: 0.9205\n",
      "Epoch 84/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0576 - accuracy: 0.9788 - val_loss: 0.4565 - val_accuracy: 0.9210\n",
      "Epoch 85/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0574 - accuracy: 0.9793 - val_loss: 0.4580 - val_accuracy: 0.9215\n",
      "Epoch 86/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0593 - accuracy: 0.9789 - val_loss: 0.4506 - val_accuracy: 0.9203\n",
      "Epoch 87/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0541 - accuracy: 0.9794 - val_loss: 0.4817 - val_accuracy: 0.9196\n",
      "Epoch 88/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0528 - accuracy: 0.9804 - val_loss: 0.4885 - val_accuracy: 0.9208\n",
      "Epoch 89/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0530 - accuracy: 0.9808 - val_loss: 0.4515 - val_accuracy: 0.9210\n",
      "Epoch 90/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9802 - val_loss: 0.4719 - val_accuracy: 0.9236\n",
      "Epoch 91/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0556 - accuracy: 0.9808 - val_loss: 0.4981 - val_accuracy: 0.9200\n",
      "Epoch 92/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0558 - accuracy: 0.9787 - val_loss: 0.4368 - val_accuracy: 0.9231\n",
      "Epoch 93/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0577 - accuracy: 0.9785 - val_loss: 0.4937 - val_accuracy: 0.9206\n",
      "Epoch 94/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.4750 - val_accuracy: 0.9227\n",
      "Epoch 95/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0525 - accuracy: 0.9807 - val_loss: 0.4977 - val_accuracy: 0.9215\n",
      "Epoch 96/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0561 - accuracy: 0.9799 - val_loss: 0.4686 - val_accuracy: 0.9238\n",
      "Epoch 97/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0503 - accuracy: 0.9818 - val_loss: 0.4939 - val_accuracy: 0.9169\n",
      "Epoch 98/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0540 - accuracy: 0.9805 - val_loss: 0.4747 - val_accuracy: 0.9202\n",
      "Epoch 99/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0539 - accuracy: 0.9809 - val_loss: 0.4895 - val_accuracy: 0.9220\n",
      "Epoch 100/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0553 - accuracy: 0.9803 - val_loss: 0.5103 - val_accuracy: 0.9203\n",
      "Epoch 101/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.5103 - val_accuracy: 0.9183\n",
      "Epoch 102/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0530 - accuracy: 0.9811 - val_loss: 0.5094 - val_accuracy: 0.9197\n",
      "Epoch 103/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 0.4886 - val_accuracy: 0.9241\n",
      "Epoch 104/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.5034 - val_accuracy: 0.9203\n",
      "Epoch 105/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.5269 - val_accuracy: 0.9207\n",
      "Epoch 106/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.5207 - val_accuracy: 0.9197\n",
      "Epoch 107/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0501 - accuracy: 0.9813 - val_loss: 0.5014 - val_accuracy: 0.9224\n",
      "Epoch 108/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.5189 - val_accuracy: 0.9218\n",
      "Epoch 109/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0503 - accuracy: 0.9815 - val_loss: 0.5684 - val_accuracy: 0.9176\n",
      "Epoch 110/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 0.5474 - val_accuracy: 0.9190\n",
      "Epoch 111/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0493 - accuracy: 0.9823 - val_loss: 0.5415 - val_accuracy: 0.9192\n",
      "Epoch 112/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.5226 - val_accuracy: 0.9199\n",
      "Epoch 113/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 0.5375 - val_accuracy: 0.9211\n",
      "Epoch 114/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0480 - accuracy: 0.9826 - val_loss: 0.5514 - val_accuracy: 0.9181\n",
      "Epoch 115/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0466 - accuracy: 0.9830 - val_loss: 0.5369 - val_accuracy: 0.9202\n",
      "Epoch 116/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0543 - accuracy: 0.9793 - val_loss: 0.5357 - val_accuracy: 0.9181\n",
      "Epoch 117/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0500 - accuracy: 0.9830 - val_loss: 0.5286 - val_accuracy: 0.9192\n",
      "Epoch 118/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0487 - accuracy: 0.9821 - val_loss: 0.5314 - val_accuracy: 0.9210\n",
      "Epoch 119/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0468 - accuracy: 0.9829 - val_loss: 0.6034 - val_accuracy: 0.9216\n",
      "Epoch 120/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.5222 - val_accuracy: 0.9228\n",
      "Epoch 121/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0478 - accuracy: 0.9839 - val_loss: 0.5585 - val_accuracy: 0.9225\n",
      "Epoch 122/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0449 - accuracy: 0.9841 - val_loss: 0.5379 - val_accuracy: 0.9226\n",
      "Epoch 123/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0485 - accuracy: 0.9816 - val_loss: 0.5511 - val_accuracy: 0.9230\n",
      "Epoch 124/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.5340 - val_accuracy: 0.9203\n",
      "Epoch 125/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0502 - accuracy: 0.9824 - val_loss: 0.5713 - val_accuracy: 0.9225\n",
      "Epoch 126/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0477 - accuracy: 0.9821 - val_loss: 0.5524 - val_accuracy: 0.9231\n",
      "Epoch 127/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0478 - accuracy: 0.9826 - val_loss: 0.5140 - val_accuracy: 0.9214\n",
      "Epoch 128/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 0.5562 - val_accuracy: 0.9203\n",
      "Epoch 129/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0457 - accuracy: 0.9838 - val_loss: 0.5917 - val_accuracy: 0.9211\n",
      "Epoch 130/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.5632 - val_accuracy: 0.9235\n",
      "Epoch 131/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0463 - accuracy: 0.9843 - val_loss: 0.5480 - val_accuracy: 0.9190\n",
      "Epoch 132/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0455 - accuracy: 0.9839 - val_loss: 0.5711 - val_accuracy: 0.9190\n",
      "Epoch 133/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.5687 - val_accuracy: 0.9207\n",
      "Epoch 134/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0475 - accuracy: 0.9839 - val_loss: 0.5723 - val_accuracy: 0.9185\n",
      "Epoch 135/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.5730 - val_accuracy: 0.9220\n",
      "Epoch 136/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 0.5994 - val_accuracy: 0.9202\n",
      "Epoch 137/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0450 - accuracy: 0.9843 - val_loss: 0.5293 - val_accuracy: 0.9236\n",
      "Epoch 138/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0438 - accuracy: 0.9838 - val_loss: 0.5679 - val_accuracy: 0.9233\n",
      "Epoch 139/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0466 - accuracy: 0.9840 - val_loss: 0.5303 - val_accuracy: 0.9208\n",
      "Epoch 140/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.5319 - val_accuracy: 0.9230\n",
      "Epoch 141/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.5388 - val_accuracy: 0.9205\n",
      "Epoch 142/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9840 - val_loss: 0.5797 - val_accuracy: 0.9216\n",
      "Epoch 143/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0471 - accuracy: 0.9835 - val_loss: 0.5491 - val_accuracy: 0.9252\n",
      "Epoch 144/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0466 - accuracy: 0.9835 - val_loss: 0.5756 - val_accuracy: 0.9205\n",
      "Epoch 145/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.6032 - val_accuracy: 0.9192\n",
      "Epoch 146/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.5471 - val_accuracy: 0.9214\n",
      "Epoch 147/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0496 - accuracy: 0.9829 - val_loss: 0.5681 - val_accuracy: 0.9238\n",
      "Epoch 148/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.5531 - val_accuracy: 0.9209\n",
      "Epoch 149/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0478 - accuracy: 0.9840 - val_loss: 0.5981 - val_accuracy: 0.9202\n",
      "Epoch 150/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 0.5924 - val_accuracy: 0.9196\n",
      "Epoch 151/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0441 - accuracy: 0.9840 - val_loss: 0.5804 - val_accuracy: 0.9216\n",
      "Epoch 152/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.5993 - val_accuracy: 0.9210\n",
      "Epoch 153/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0448 - accuracy: 0.9841 - val_loss: 0.5828 - val_accuracy: 0.9228\n",
      "Epoch 154/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.5798 - val_accuracy: 0.9187\n",
      "Epoch 155/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.6333 - val_accuracy: 0.9208\n",
      "Epoch 156/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.6039 - val_accuracy: 0.9205\n",
      "Epoch 157/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0418 - accuracy: 0.9853 - val_loss: 0.5817 - val_accuracy: 0.9207\n",
      "Epoch 158/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 0.5771 - val_accuracy: 0.9208\n",
      "Epoch 159/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0431 - accuracy: 0.9851 - val_loss: 0.6335 - val_accuracy: 0.9190\n",
      "Epoch 160/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.5635 - val_accuracy: 0.9201\n",
      "Epoch 161/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.6470 - val_accuracy: 0.9189\n",
      "Epoch 162/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0442 - accuracy: 0.9855 - val_loss: 0.6589 - val_accuracy: 0.9201\n",
      "Epoch 163/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.6244 - val_accuracy: 0.9190\n",
      "Epoch 164/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0437 - accuracy: 0.9850 - val_loss: 0.5943 - val_accuracy: 0.9184\n",
      "Epoch 165/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 0.6678 - val_accuracy: 0.9187\n",
      "Epoch 166/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0463 - accuracy: 0.9848 - val_loss: 0.6480 - val_accuracy: 0.9208\n",
      "Epoch 167/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0410 - accuracy: 0.9854 - val_loss: 0.5964 - val_accuracy: 0.9217\n",
      "Epoch 168/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.6591 - val_accuracy: 0.9202\n",
      "Epoch 169/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0379 - accuracy: 0.9860 - val_loss: 0.6464 - val_accuracy: 0.9188\n",
      "Epoch 170/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.5933 - val_accuracy: 0.9188\n",
      "Epoch 171/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.5866 - val_accuracy: 0.9195\n",
      "Epoch 172/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.6182 - val_accuracy: 0.9217\n",
      "Epoch 173/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.6006 - val_accuracy: 0.9203\n",
      "Epoch 174/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.6194 - val_accuracy: 0.9192\n",
      "Epoch 175/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.6131 - val_accuracy: 0.9202\n",
      "Epoch 176/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.6281 - val_accuracy: 0.9212\n",
      "Epoch 177/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 0.6146 - val_accuracy: 0.9206\n",
      "Epoch 178/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.5921 - val_accuracy: 0.9209\n",
      "Epoch 179/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.6355 - val_accuracy: 0.9201\n",
      "Epoch 180/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0390 - accuracy: 0.9870 - val_loss: 0.6240 - val_accuracy: 0.9206\n",
      "Epoch 181/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0413 - accuracy: 0.9862 - val_loss: 0.6456 - val_accuracy: 0.9201\n",
      "Epoch 182/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0416 - accuracy: 0.9863 - val_loss: 0.6480 - val_accuracy: 0.9202\n",
      "Epoch 183/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.6500 - val_accuracy: 0.9225\n",
      "Epoch 184/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.6144 - val_accuracy: 0.9215\n",
      "Epoch 185/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0379 - accuracy: 0.9866 - val_loss: 0.6201 - val_accuracy: 0.9212\n",
      "Epoch 186/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.6316 - val_accuracy: 0.9205\n",
      "Epoch 187/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0408 - accuracy: 0.9857 - val_loss: 0.6604 - val_accuracy: 0.9207\n",
      "Epoch 188/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.6447 - val_accuracy: 0.9212\n",
      "Epoch 189/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.6038 - val_accuracy: 0.9215\n",
      "Epoch 190/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 0.6629 - val_accuracy: 0.9215\n",
      "Epoch 191/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0423 - accuracy: 0.9859 - val_loss: 0.6554 - val_accuracy: 0.9192\n",
      "Epoch 192/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9851 - val_loss: 0.6874 - val_accuracy: 0.9213\n",
      "Epoch 193/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0391 - accuracy: 0.9864 - val_loss: 0.6402 - val_accuracy: 0.9206\n",
      "Epoch 194/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.6630 - val_accuracy: 0.9211\n",
      "Epoch 195/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0411 - accuracy: 0.9858 - val_loss: 0.6613 - val_accuracy: 0.9193\n",
      "Epoch 196/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.6533 - val_accuracy: 0.9225\n",
      "Epoch 197/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.6354 - val_accuracy: 0.9212\n",
      "Epoch 198/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.6851 - val_accuracy: 0.9206\n",
      "Epoch 199/200\n",
      "698/698 [==============================] - 3s 4ms/step - loss: 0.0397 - accuracy: 0.9860 - val_loss: 0.6615 - val_accuracy: 0.9203\n",
      "Epoch 200/200\n",
      "698/698 [==============================] - 3s 5ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 0.6083 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(x_train, y_train,\n",
    "          batch_size=86,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1619889213978,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "Jc7lrZQlbznK",
    "outputId": "5b517c84-8f3f-4c8e-8ea3-6ee0c8fb904a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fiabilité du model sur les données de test est de : 92.00000166893005  %\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "fiabiliter=acc*100\n",
    "print('La fiabilité du model sur les données de test est de :',fiabiliter,\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFs_yU-TbFB2"
   },
   "outputs": [],
   "source": [
    "#classifier.save('classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40634,
     "status": "ok",
     "timestamp": 1619889257616,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "Sh7hAWFbeRtH",
    "outputId": "42fa004c-243d-4b2c-fc9b-a9aba2b09899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.listdir(\"./\")\n",
    "os.listdir(\"./drive/MyDrive/LIFPROJET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1619889275200,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "bstm9e0heVJb"
   },
   "outputs": [],
   "source": [
    "classifier.save('./drive/MyDrive/LIFPROJET/classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvH0lOsc_pHJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1619889345337,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "-rSDFw_Iccfr",
    "outputId": "8e832bc1-aa0e-4d16-f7b7-7e2a6cc39642"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[872   0  16  10   5   1  94   0   2   0]\n",
      " [  2 979   1  10   2   0   4   0   2   0]\n",
      " [ 14   0 855   9  61   0  61   0   0   0]\n",
      " [ 10   3   9 923  26   0  27   0   2   0]\n",
      " [  1   0  54  18 877   0  50   0   0   0]\n",
      " [  0   0   0   0   0 986   0   9   0   5]\n",
      " [ 84   2  60  22  45   0 778   0   9   0]\n",
      " [  0   0   0   0   0   2   0 980   0  18]\n",
      " [  2   1   2   1   1   2   5   2 984   0]\n",
      " [  0   0   0   0   0   6   0  28   0 966]]\n",
      "\n",
      "\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      1000\n",
      "           1       0.99      0.98      0.99      1000\n",
      "           2       0.86      0.85      0.86      1000\n",
      "           3       0.93      0.92      0.93      1000\n",
      "           4       0.86      0.88      0.87      1000\n",
      "           5       0.99      0.99      0.99      1000\n",
      "           6       0.76      0.78      0.77      1000\n",
      "           7       0.96      0.98      0.97      1000\n",
      "           8       0.98      0.98      0.98      1000\n",
      "           9       0.98      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "\n",
      "Accuracy :  92.0\n"
     ]
    }
   ],
   "source": [
    "#Predict the test results\n",
    "rounded_predictions = classifier.predict_classes(x_test)\n",
    "rounded_predictions[1]\n",
    "\n",
    "y_test[1]\n",
    "import numpy as np\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "\n",
    "#confusion matrix and classification report\n",
    "print('Confusion Matrix :\\n',confusion_matrix(rounded_labels, rounded_predictions))\n",
    "print('\\n')\n",
    "print('Classification Report :\\n',classification_report(rounded_labels, rounded_predictions))\n",
    "print('\\n')\n",
    "print('Accuracy : ' ,accuracy_score(rounded_labels, rounded_predictions)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1619889350412,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "uGSQOTg9eDfY"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "batches = datagen.flow(x_train, y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1619424,
     "status": "ok",
     "timestamp": 1619890973329,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "OUG6aSUUeDfc",
    "outputId": "7cebcc08-28d9-4f18-edad-2415b9a7e434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.8264 - accuracy: 0.7193\n",
      "Epoch 2/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.6563 - accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.6051 - accuracy: 0.7785\n",
      "Epoch 4/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.5738 - accuracy: 0.7866\n",
      "Epoch 5/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.5509 - accuracy: 0.7952\n",
      "Epoch 6/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.5298 - accuracy: 0.8026\n",
      "Epoch 7/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.5130 - accuracy: 0.8096\n",
      "Epoch 8/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4991 - accuracy: 0.8150\n",
      "Epoch 9/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4937 - accuracy: 0.8165\n",
      "Epoch 10/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4846 - accuracy: 0.8192\n",
      "Epoch 11/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4785 - accuracy: 0.8229\n",
      "Epoch 12/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4667 - accuracy: 0.8257\n",
      "Epoch 13/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4603 - accuracy: 0.8283\n",
      "Epoch 14/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4556 - accuracy: 0.8303\n",
      "Epoch 15/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4522 - accuracy: 0.8306\n",
      "Epoch 16/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4465 - accuracy: 0.8344\n",
      "Epoch 17/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4454 - accuracy: 0.8351\n",
      "Epoch 18/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4412 - accuracy: 0.8346\n",
      "Epoch 19/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4372 - accuracy: 0.8378\n",
      "Epoch 20/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4307 - accuracy: 0.8402\n",
      "Epoch 21/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4294 - accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4275 - accuracy: 0.8421\n",
      "Epoch 23/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4224 - accuracy: 0.8421\n",
      "Epoch 24/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4203 - accuracy: 0.8434\n",
      "Epoch 25/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4149 - accuracy: 0.8467\n",
      "Epoch 26/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4144 - accuracy: 0.8462\n",
      "Epoch 27/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4136 - accuracy: 0.8468\n",
      "Epoch 28/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4100 - accuracy: 0.8489\n",
      "Epoch 29/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4071 - accuracy: 0.8486\n",
      "Epoch 30/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4058 - accuracy: 0.8475\n",
      "Epoch 31/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4032 - accuracy: 0.8493\n",
      "Epoch 32/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3983 - accuracy: 0.8518\n",
      "Epoch 33/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.4019 - accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3995 - accuracy: 0.8515\n",
      "Epoch 35/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3933 - accuracy: 0.8536\n",
      "Epoch 36/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3993 - accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3946 - accuracy: 0.8532\n",
      "Epoch 38/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3940 - accuracy: 0.8540\n",
      "Epoch 39/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3910 - accuracy: 0.8542\n",
      "Epoch 40/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3931 - accuracy: 0.8534\n",
      "Epoch 41/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3906 - accuracy: 0.8539\n",
      "Epoch 42/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3890 - accuracy: 0.8564\n",
      "Epoch 43/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3866 - accuracy: 0.8568\n",
      "Epoch 44/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3869 - accuracy: 0.8564\n",
      "Epoch 45/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3888 - accuracy: 0.8558\n",
      "Epoch 46/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3817 - accuracy: 0.8566\n",
      "Epoch 47/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3811 - accuracy: 0.8568\n",
      "Epoch 48/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3815 - accuracy: 0.8568\n",
      "Epoch 49/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3769 - accuracy: 0.8579\n",
      "Epoch 50/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3802 - accuracy: 0.8598\n",
      "Epoch 51/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3691 - accuracy: 0.8614\n",
      "Epoch 52/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3795 - accuracy: 0.8599\n",
      "Epoch 53/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3776 - accuracy: 0.8603\n",
      "Epoch 54/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3766 - accuracy: 0.8613\n",
      "Epoch 55/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3723 - accuracy: 0.8601\n",
      "Epoch 56/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3734 - accuracy: 0.8611\n",
      "Epoch 57/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3719 - accuracy: 0.8616\n",
      "Epoch 58/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3714 - accuracy: 0.8620\n",
      "Epoch 59/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3705 - accuracy: 0.8615\n",
      "Epoch 60/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3722 - accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3708 - accuracy: 0.8631\n",
      "Epoch 62/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3718 - accuracy: 0.8609\n",
      "Epoch 63/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3719 - accuracy: 0.8620\n",
      "Epoch 64/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3675 - accuracy: 0.8636\n",
      "Epoch 65/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3692 - accuracy: 0.8621\n",
      "Epoch 66/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3676 - accuracy: 0.8634\n",
      "Epoch 67/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3666 - accuracy: 0.8644\n",
      "Epoch 68/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3691 - accuracy: 0.8619\n",
      "Epoch 69/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3666 - accuracy: 0.8647\n",
      "Epoch 70/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3619 - accuracy: 0.8643\n",
      "Epoch 71/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3657 - accuracy: 0.8631\n",
      "Epoch 72/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3665 - accuracy: 0.8628\n",
      "Epoch 73/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3630 - accuracy: 0.8648\n",
      "Epoch 74/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3616 - accuracy: 0.8654\n",
      "Epoch 75/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3623 - accuracy: 0.8646\n",
      "Epoch 76/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3641 - accuracy: 0.8634\n",
      "Epoch 77/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3640 - accuracy: 0.8658\n",
      "Epoch 78/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3613 - accuracy: 0.8658\n",
      "Epoch 79/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3626 - accuracy: 0.8660\n",
      "Epoch 80/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3569 - accuracy: 0.8668\n",
      "Epoch 81/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3615 - accuracy: 0.8653\n",
      "Epoch 82/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3583 - accuracy: 0.8668\n",
      "Epoch 83/100\n",
      "937/937 [==============================] - 16s 18ms/step - loss: 0.3565 - accuracy: 0.8670\n",
      "Epoch 84/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3634 - accuracy: 0.8638\n",
      "Epoch 85/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3555 - accuracy: 0.8677\n",
      "Epoch 86/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3571 - accuracy: 0.8671\n",
      "Epoch 87/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3588 - accuracy: 0.8684\n",
      "Epoch 88/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3587 - accuracy: 0.8665\n",
      "Epoch 89/100\n",
      "937/937 [==============================] - 16s 18ms/step - loss: 0.3603 - accuracy: 0.8663\n",
      "Epoch 90/100\n",
      "937/937 [==============================] - 16s 18ms/step - loss: 0.3560 - accuracy: 0.8674\n",
      "Epoch 91/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3522 - accuracy: 0.8675\n",
      "Epoch 92/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3568 - accuracy: 0.8672\n",
      "Epoch 93/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3588 - accuracy: 0.8665\n",
      "Epoch 94/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3530 - accuracy: 0.8680\n",
      "Epoch 95/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3526 - accuracy: 0.8691\n",
      "Epoch 96/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3521 - accuracy: 0.8696\n",
      "Epoch 97/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3564 - accuracy: 0.8683\n",
      "Epoch 98/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3521 - accuracy: 0.8667\n",
      "Epoch 99/100\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.3552 - accuracy: 0.8681\n",
      "Epoch 100/100\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.3540 - accuracy: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda3c2a9050>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(batches, steps_per_epoch = len(x_train)//64, epochs=100,\n",
    "                      use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1847,
     "status": "ok",
     "timestamp": 1619890998697,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "a5lu5yB-eDfe",
    "outputId": "6c54aa5d-e434-4afc-f59f-524420238509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fiabilité du model avec des filtres sur les données de test est de : 90.23000001907349  %\n"
     ]
    }
   ],
   "source": [
    "loss, acc = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "fiabiliter=acc*100\n",
    "print('La fiabilité du model avec des filtres sur les données de test est de :',fiabiliter,\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1619891024380,
     "user": {
      "displayName": "cirine salah",
      "photoUrl": "",
      "userId": "17657959173685329521"
     },
     "user_tz": -120
    },
    "id": "WW_-_3oMmRl6"
   },
   "outputs": [],
   "source": [
    "classifier.save('./drive/MyDrive/LIFPROJET/classification_model_ImageDataGenerator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhSfF6wweDff"
   },
   "source": [
    "# \"LOAD_IMAGE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5L2GcB_VeDfg"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def plot_image(prediction, img):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    predicted_label = np.argmax(prediction,axis = -1)\n",
    "    plt.xlabel(\"{} {:2.0f}%\".format(class_names[predicted_label],\n",
    "               100*np.max(prediction),\n",
    "               ),\n",
    "                color=\"blue\")\n",
    "    \n",
    "def plot_value_array(prediction):\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), prediction, color=\"red\")\n",
    "    plt.ylim([0,1])\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    thisplot[predicted_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jwLXIFaYeDfg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a002a2bd41f8>:19: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "8\n",
      "Bag\n"
     ]
    }
   ],
   "source": [
    "# Function to load and prepare the image in right shape\n",
    "def load_image(filename):\n",
    "    # Load the image\n",
    "    img = load_img(filename, color_mode = \"grayscale\", target_size=(28, 28))\n",
    "    # Convert the image to array\n",
    "    img = img_to_array(img)\n",
    "    # Reshape the image into a sample of 1 channel\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    # Prepare it as pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# Load an image and predict the apparel class\n",
    "img = load_image('./static/images/sac.jpg')\n",
    "# Load the saved model\n",
    "classifier = load_model('classification_model.h5')\n",
    "# Predict the apparel class\n",
    "class_prediction = classifier.predict_classes(img)\n",
    "print(class_prediction[0])\n",
    "\n",
    "#Map apparel category with the numerical class\n",
    "if class_prediction[0] == 0:\n",
    "  product = \"T-shirt/top\"\n",
    "elif class_prediction[0] == 1:\n",
    "  product = \"Trouser\"\n",
    "elif class_prediction[0] == 2:\n",
    "  product = \"Pullover\"\n",
    "elif class_prediction[0] == 3:\n",
    "  product = \"Dress\"\n",
    "elif class_prediction[0] == 4:\n",
    "  product = \"Coat\"\n",
    "elif class_prediction[0] == 5:\n",
    "  product = \"Sandal\"\n",
    "elif class_prediction[0] == 6:\n",
    "  product = \"Shirt\"\n",
    "elif class_prediction[0] == 7:\n",
    "  product = \"Sneaker\"\n",
    "elif class_prediction[0] == 8:\n",
    "  product = \"Bag\"\n",
    "else:\n",
    "  product = \"Ankle boot\"\n",
    "\n",
    "print(product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Yq_yTqRseDfh",
    "outputId": "0e4e9996-c234-44aa-8f4d-6b33111d6a98"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAARkUlEQVR4nO3deYxe1XnH8d+Dl7HHCwab2ATbcVxiREor4g6WqcGiJgXSpOmS/EFoKygtbdW0kG5pUnURaqWqoiuqcEVCIqoAIQXSBaIEypYuLB6z2WAaAoHYQGws4nUM4zFP/3gvMfg+h7l3PPM+nvH3I438+sw57z33tf3zmXvOudfcXQCA7jsmuwMAcLQigAEgCQEMAEkIYABIQgADQJLJ2R0Ass2bN8+XLFmS3Q1MUOvXr9/u7idE3yOAcdRbsmSJ+vv7s7uBCcrMXih9j0sQAJCEAAaAJAQwACQhgAEgCQEMAEkIYABIQgADQBICGACSEMAAkIQABoAkBDAAJCGAASAJAQwASQhgAEhCAANAEgIYAJIQwACQhAAGgCQEMAAkIYABIAkBDABJCGAASEIAA0ASAhgAkhDAAJCEAAaAJAQwACQhgAEgCQEMAEkIYABIQgADQJLJbSqbmY9VRwBJcnfL7gPQLYyAASAJAQwASQhgAEhCAANAEgIYAJIQwACQhAAGgCQEMAAkIYABIEmrnXDoOP/882tlPT09jdsPDAzUyu67776w7tDQUOP3BTC+MAIGgCQEMAAkIYABIAkBDABJmIR7B5dffnlYfvXVV4/6sVasWBGWr1u3rlbmzl1BgYmAETAAJCGAASAJAQwASQhgAEhCAANAElZBVM4555xa2Visdih5+OGHw/KVK1fWyh588MGx7g6ALmAEDABJCGAASEIAA0ASAhgAkhx1k3Dz5s0Ly0899dRaWekevd00d+7cWllfX19Yt7+/f6y7A2AUMQIGgCQEMAAkIYABIAkBDABJCGAASHLUrYI4+eSTw/K1a9d2uSfN3HHHHbWyVatWJfQEwGhjBAwASQhgABPaggWSWbOvBQu62zcCGMCEtnXr2NQdDQQwACQ56ibhli1bFpaPp3vsvvrqq9ldADAKGAEDQBICGACSEMAAkIQABoAkBDAAJDnqVkEsXrw4uwuH7ayzzgrLn3766VqZu491dwCMECNgAEhCAANAEgIYAJIQwACQZEJPwkX3/l24cGFCT0bXjh07wvKLLrqoVnbDDTeMcW8AjBQjYABIQgADQBICGACSEMAAkIQABoAkE3oVxKRJk2plt956a0JPRtfQ0FBYvm/fvi73BMDhYAQMAEkIYABIQgADQBICGACSHLGTcMuXLw/L58+fXysrTT499thjtbKTTjoprLt69epa2WuvvRbWnTlzZq0smhiLJgFLBgcHw/JZs2Y17teUKVNqZWvWrGlct9SHe++9NywHcHgYAQNAEgIYAJIQwACQhAAGgCQEMAAkOSJWQUyeXO/GgQMHwrrRiofS1tzzzjuvVrZr166w7sDAQK0sWu1Qsn///lqZmYV1o3ObPn16WDc63wULFoR1t27dWivr6ekJ6+7du7dWFq24kKRjjqn/P/3GG2+EdQE0xwgYAJIQwACQhAAGgCQEMAAkOSIm4W6++eZa2ZVXXhnW3blzZ61s9uzZYd3NmzfXyqIJP0maOnVqrWz37t1h3WjCLJoIjN6zJNoaLMWTZaWt19FEYmlyb8aMGbWy0hZnJuGAscEIGACSEMAAkIQABoAkBDAAJDF3b17ZrHnlFpYuXVoriyaJJGnatGm1stJ9d08//fRa2T333BPWPfbYY2tlpQm7OXPm1MpeeumlWllpJ1004Vba+RdNMJbqLlu2rFa2YcOGsG6ktGsu+hxuv/32xu/bhrvH2wfHUF9fn/f393f7sOiSwobUohaR2PD4tt7d+6LvMQIGgCQEMAAkIYABIAkBDABJCGAASHJEbEWOVjGU7qUbzciXtvE+/vjjtbJotUOpD6VVEE3v0Vu693C08qR0T+PoWKVVH88880zj922zvbj0OQA4PIyAASAJAQwASQhgAEhCAANAkq7Orlx22WVh+d13310riyaJpHgCqzTZFU3O9fb2hnWjya7SNu3oPr/RvXSjB3VK8blFW6xLSvcpPu6442plpUm4aNtx6T7D0YRoaWKudDwAdYyAASAJAQwASQhgAEhCAANAEgIYAJJ0dRXE/fffH5a3eXpwtNqgtIIgmpGPnjIsxTeAf/3118O60aqLaFVAqV/RDdWjpz2XlG5WH/W3dPP26LMprfqIzveCCy4I647VjdqBiYgRMAAkIYABIAkBDABJCGAASNLVSbjSpFQ0eVS6x2+0Dbe0bXnWrFmN2kvSwMBAraw02bVjx45aWXRupXOI+lt6InE0WVaqG32OpQnOqA+lrdPRubWZOAUQYwQMAEkIYABIQgADQBICGACSEMAAkKT1KohDZ89LKxCiLbClWfZoG29pW2w0I19arTA4OFgrK83eR08aLm3jjfoQnUO0bbpN+1K/SlukoxUTpScoR59vadVG1N/os5Xi8yg9bXmk9YCJghEwACQhgAEgCQEMAEkIYABIctiTcCXR5E9pkqfNcaIJodJkVzQ5V6rbRtSHaCtzmwm/6MnDpfI2T2sufeZtPofoeKX2UX9LE4GH1i1N0gITFSNgAEhCAANAEgIYAJIQwACQhAAGgCRdvSF7aWtvNFNfmjmPZvpL22Kj47V5gnJpVj5aFdDb29voPUvt26xWKG1bjj6H0mqS6PMtra5os7Jh+vTpjdpHSn8/gImKETAAJCGAASAJAQwASQhgAEjS1Um40uRRNNlV2sYbTWyVJo+i9y1NCEV9K9WNJsyiya7S/W2j921z7+CS6DNrs2W4dL7RNuvSJFw0GdnU3r17R9wWGI8YAQNAEgIYAJIQwACQhAAGgCQEMAAkabUKwswabysttY9EN04vrYKIzJ49OyzfvXt3raynpyesu3PnzlpZaUY/eipxdA5tnkhcWskRrWIo9StanRGdlxRvGS6tuNi3b1+j9qU+lM7tUIfzdwsYjxgBA0ASAhgAkhDAAJCEAAaAJIe9FbnNxElpkqc0oROJJtFKfTj++ONrZaXt0G3u5xtNEEb3si1NwkWfQ6lu9L6lewdHW68XLVoU1t2zZ0+jfknS/Pnza2Xbt28P60afY+k+v6PxhGpgPGMEDABJCGAASNLVu6EBGEbbtdAN11jjyMQIGACSEMAAkKT1JYhDVxyUnrobefbZZ8Pya665plY2d+7csO7ixYtrZaWVDdFqhZkzZ4Z126xMiM45WjFRah/VLd28Pdr2HK1gkOKt16UnO0flpRuib9u2rVZ21VVXhXVffPHFWllpFcShW5RLq06AiYoRMAAkIYABIAkBDABJCGAASHLYk3Cle71G24NLk0eXXnrpiI9fKnuncrS7J3GbukykAc0xAgaAJAQwACQhgAEgCQEMAEkIYABI0noVxKGz36WVBk2fhCuVt8s2xWqHsdXmzxJAc4yAASAJAQwASQhgAEhCAANAklaTcO6+fXBw8IWx6gyOeu/J7gDQTW0D+ISx6ggAHG24BAEASQhgAEhCAANAEgJYkpmWmGnjGL33YjPdaaZNZnrKTEuq8jVmesRMG810vVnneryZPmamJ830X2aaW5X9kJm+PBb9A5CHAB57/yzpKnedKmmFpG1mOkbS9ZIudNdpkl6QdHFV//ckrazaXVSV/YWkP+lqrwGMOQL4oMnVSPQJM91ipl5JMtOfmmldNVK91kxWlZ9R1X3ATFdFI2gzvV/SZHfdJUnu2uOuAUlzJb3urm9VVe+S9LHq9RuSeiT1StpvprMlveyuZ8by5AF0HwF80CmSrnXXj0raJek3q/J/dNcZ1Uh1uqSPVOVflPQb7jpT0oHCey6TtMNMt5np0SqoJ0naLmmKmfqqeh+XtKh6faWkb0j6oKSbJP2xpD8ftbMEcMQggA/a7K7/qV5/SdJZ1eufMNNDZtogaY2kHzbTHEmz3PW/VZ0bC+85WdLZkn5f0hmSlkq6xF0u6UJJf2emhyXtljQkSe66y10/5q6flvSzkr4m6ZRqVP65N0fmAMY/AvigQ++56GaaJukaSR93149I+pykaZKa3v9yi6RH3fWcu4Yk/auk5ZLkrgfcdba7Vkj6pvT2SwxV0F5cHf8vJV0qab2kXxjBuQE4AhHABy0205nV609I+m91wlaStptppjqXCuSu70vabaaV1fcvLLznOknHmenNHYRrJD0lSWZ6V/Vrj6Q/lPRPh7T9tKR/cNd+dS59uDrXhxkBAxMEAXzQJkkXm+kJScdLWuuuHeqMejeoM3pd95b6vyLpWjM9oM6IeOehb+iuA+pcfri7uoRh1ftJ0h+YaZOkJyT9h7vuebOdmd4tqc9d/1YV/Y2kB9UZEZcudwAYZ4ynHYyMmWa6a0/1+jOSTnTXFcndwgj09fV5f39/djc62j7dhX+/w8r+SM1svbv3Rd9r/Ugi/MCHzfRZdT7DFyRdktsdAOMNATxC7rpZ0s3Z/QAwfnENGACSEMAAkIQABoAkBDAAJCGAASAJAQwASQhgAEhCAANAEgIYAJIQwACQhAAGgCQEMAAk4WY8wDvJvpdhN7Q5x/F4fkcwAhiYKAjScYdLEACQhBEwgO5ipP4DjIABIAnPhMNRz8xeUeexUm3Mk7R9BIej3ZFzzG61e4+7nxB9gwAGRsDM+ksPWqRd+3YZx8w4x0NxCQIAkhDAAJCEAAZG5lrajWq7jGNmnOPbcA0YAJIwAgaAJAQwACQhgIEWzOwCM/s/M/u2mX2mRbsvmNk2M9vY8niLzOxeM9tkZk+a2RUN200zs4fN7PGq3ZUtjzvJzB41s9tbtHnezDaY2WNm1t+i3Rwzu8XMnq7O88wGbU6pjvPm1y4z+1TD4/1O9ZlsNLObzGxaw3ZXVG2ebHqsYbk7X3zx1eBL0iRJz0paKmmqpMclvb9h29WSlkva2PKYJ0paXr2eJelbTY4pySTNrF5PkfSQpJUtjvu7km6UdHuLNs9LmjeCz/V6Sb9avZ4qac4I/ly+p86Gh+HqniTpO5KmV7//iqRLGrQ7TdJGSb3q3MLhPyW973D/TjECBppbIenb7v6cuw9K+rKkn2nS0N2/KenVtgd095fd/ZHq9W5Jm9QJkeHaubvvqX47pfpqNONuZgslfVjS59v2ty0zm63Of07XSZK7D7r7jpZvc66kZ9296W7GyZKmm9lkdQL1pQZtTpX0oLsPuPuQpPsl/VzLftYQwEBzJ0na/Jbfb1GDMBwtZrZE0gfUGc02qT/JzB6TtE3SXe7eqJ2kv5f0aUlvtOyiS7rTzNab2a81bLNU0iuSvlhd8vi8mc1oedwLJd3UqIPuL0r6a0nflfSypJ3ufmeDphslrTazuWbWK+mnJC1q2c8aAhhoLrqNV1fWcZrZTEm3SvqUu+9q0sbdD7j76ZIWSlphZqc1OM5HJG1z9/Uj6OYqd18u6UOSPmlmqxu0mazOpZm17v4BSXsltbm2PlXSRyX9S8P6x6nzU8t7Jb1b0gwz+8Xh2rn7Jkl/JekuSV9X5/LTUNN+lhDAQHNb9PZRz0I1+/H1sJjZFHXC9wZ3v61t++pH+vskXdCg+ipJHzWz59W5xLLGzL7U8DgvVb9uk/RVdS7ZDGeLpC1vGZ3fok4gN/UhSY+4+9aG9T8o6Tvu/oq775d0m6Qfb9LQ3a9z9+Xuvlqdy0nPtOhniAAGmlsn6X1m9t5q5HWhpH8fywOamalzfXSTu/9ti3YnmNmc6vV0dYLn6eHauftn3X2huy9R5/zucfdhR4hmNsPMZr35WtJ56vzYPtzxvidps5mdUhWdK+mp4dq9xSfU8PJD5buSVppZb/XZnqvOdfVhmdm7ql8XS/r5lscNcUN2oCF3HzKz35L0DXVm3r/g7k82aWtmN0k6R9I8M9si6c/c/boGTVdJ+iVJG6rruZL0R+7+tWHanSjpejObpM5A6yvu3nhJ2QjMl/TVTqZpsqQb3f3rDdv+tqQbqv/UnpP0y00aVddif1LSrzftpLs/ZGa3SHpEnUsIj6r51uJbzWyupP2SPunu32963BK2IgNAEi5BAEASAhgAkhDAAJCEAAaAJAQwACQhgAEgCQEMAEn+H9CkTJjY9/7YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = classifier.predict(img)\n",
    "for i in range(1):\n",
    "    # image\n",
    "    plt.subplot(1, 2, 2*i+1)\n",
    "    plot_image(preds[i], img[i])\n",
    "    # bar chart\n",
    "    plt.subplot(1, 2, 2*i+2)\n",
    "    plot_value_array(preds[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyv1nBDaeDfj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification_modele.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
